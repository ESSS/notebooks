{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsum Notebook - Einstein Summation\n",
    "\n",
    "## Einstein Notation\n",
    "In mathematics, especially in applications of linear algebra to physics, the Einstein notation or Einstein summation convention is a notational convention that implies summation over a set of indexed terms in a formula, thus achieving notational brevity. It was introduced to physics by Albert Einstein in 1916.\n",
    "\n",
    "The following\n",
    "$$\n",
    "y = \\sum^3_{i=1} c_i x_i = c_1 x_1 + c_2 x_2 + c_3 x_3\n",
    "$$\n",
    "is reduced to\n",
    "$$\n",
    "y = c_i x_i\n",
    "$$\n",
    "\n",
    "### Inner Product\n",
    "$$\n",
    "\\mathbf{u} \\cdot \\mathbf{v} = u_i v_i\n",
    "$$\n",
    "\n",
    "### Matrix Product\n",
    "$$\n",
    "\\mathbf{C} = \\mathbf{A} \\mathbf{B} = A_{ij} B_{jk} = C_{ik}\n",
    "$$\n",
    "\n",
    "### Matrix Trace\n",
    "The trace of a matrix, $tr(A) = \\sum_i A_ii$ is calculated by\n",
    "$$\n",
    "tr(A) = A_{ii}\n",
    "$$\n",
    "\n",
    "### NumPy Einsum\n",
    "```\n",
    "numpy.einsum(subscripts, *operands, out=None, dtype=None, order='K', casting='safe')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's try some stuff out. The example below shows how a dot product is represented using einsum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot using np.dot is 24.0\n",
      "Dot using np.einsum is 24.0\n",
      "[ 1.  2.  4.  3.]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([1.0, 2.0, 4.0, 3.0])\n",
    "v = np.array([3.0, 1.0, 1.0, 5.0])\n",
    "\n",
    "\n",
    "print('Dot using np.dot is', np.dot(u, v))\n",
    "print('Dot using np.einsum is', np.einsum('i,i', u, v))\n",
    "print(np.einsum('i',u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace using np.trace is 3.1\n",
      "\n",
      "Trace using np.einsum is 3.1\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1.0, 2.0, 4.0, 3.0],\n",
    "              [1.0, 0.0, 2.0, 0.0],\n",
    "              [1.0, 1.0, 1.1, 0.0],\n",
    "              [2.0, 2.0, 1.0, 1.0]])\n",
    "\n",
    "B = np.array([[1.0, 2.0, 4.0, 3.0],\n",
    "              [0.0, 1.0, 0.0, 0.0],\n",
    "              [1.0, 1.0, 1.0, 1.0],\n",
    "              [7.0, 8.0, 9.0, 1.0]])\n",
    "\n",
    "\n",
    "Cdot = np.dot(A, B)\n",
    "Cein = np.einsum('jw,wk', A, B)\n",
    "\n",
    "assert np.allclose(Cdot, Cein)\n",
    "\n",
    "print('Trace using np.trace is', np.trace(A))\n",
    "print('\\nTrace using np.einsum is',np.einsum('ii', A))\n",
    "#print np.einsum('ij', A)\n",
    "#print np.einsum('ji', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix-vector product using np.dot is\n",
      " [ 30.    9.    7.4  13. ]\n",
      "\n",
      "Matrix-vector product using np.einsum is\n",
      " [ 30.    9.    7.4  13. ]\n"
     ]
    }
   ],
   "source": [
    "print('Matrix-vector product using np.dot is\\n', np.dot(A, u))\n",
    "print('\\nMatrix-vector product using np.einsum is\\n', np.einsum('ij,j', A, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.   12.   15.4   6. ]\n",
      "[ 13.   12.   15.4   6. ]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(A.T, u))\n",
    "print(np.einsum('qj,q', A, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting will use the \"`...`\" syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is\n",
      " [[ 1.   2.   4.   3. ]\n",
      " [ 1.   0.   2.   0. ]\n",
      " [ 1.   1.   1.1  0. ]\n",
      " [ 2.   2.   1.   1. ]]\n",
      "\n",
      "U is\n",
      " [ 1.  2.  4.  3.]\n",
      "\n",
      "A*u is\n",
      " [[  1.    4.   16.    9. ]\n",
      " [  1.    0.    8.    0. ]\n",
      " [  1.    2.    4.4   0. ]\n",
      " [  2.    4.    4.    3. ]]\n",
      "\n",
      "np.einsum is\n",
      " [[  1.    4.   16.    9. ]\n",
      " [  1.    0.    8.    0. ]\n",
      " [  1.    2.    4.4   0. ]\n",
      " [  2.    4.    4.    3. ]]\n"
     ]
    }
   ],
   "source": [
    "# Multiply each line of A by u pointwise\n",
    "print('A is\\n', A)\n",
    "print('\\nU is\\n', u)\n",
    "print('\\nA*u is\\n', A*u)\n",
    "print('\\nnp.einsum is\\n', np.einsum('...j,j->...j', A, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "np.einsum is\n",
      " [ 10.    3.    3.1   6. ]\n"
     ]
    }
   ],
   "source": [
    "print('\\nnp.einsum is\\n', np.einsum('...j->...', A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's check performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting\n",
      "\n",
      "A*b\n",
      "100 loops, best of 3: 2.95 ms per loop\n",
      "\n",
      "np.einsum('...j,j->...j', A, b)\n",
      "100 loops, best of 3: 3.44 ms per loop\n",
      "\n",
      "Matrix Vector Product\n",
      "\n",
      "np.dot(A, b)\n",
      "The slowest run took 12.83 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 183 µs per loop\n",
      "\n",
      "np.einsum('...j,j', A, b)\n",
      "1000 loops, best of 3: 433 µs per loop\n",
      "\n",
      "Matrix Product\n",
      "\n",
      "np.dot(A, B)\n",
      "10 loops, best of 3: 35.6 ms per loop\n",
      "\n",
      "np.einsum('ij,jk', A, B)\n",
      "1 loop, best of 3: 442 ms per loop\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(1000,1000)\n",
    "B = np.random.rand(1000,1000)\n",
    "b = np.random.rand(1000)\n",
    "\n",
    "print ('Broadcasting')\n",
    "\n",
    "print ('\\nA*b')\n",
    "%timeit A*b\n",
    "\n",
    "print (\"\\nnp.einsum('...j,j->...j', A, b)\")\n",
    "%timeit np.einsum('...j,j->...j', A, b)\n",
    "\n",
    "print ('\\nMatrix Vector Product')\n",
    "\n",
    "print ('\\nnp.dot(A, b)')\n",
    "%timeit np.dot(A, b)\n",
    "\n",
    "print (\"\\nnp.einsum('...j,j', A, b)\")\n",
    "%timeit np.einsum('...j,j', A, b)\n",
    "\n",
    "print ('\\nMatrix Product')\n",
    "\n",
    "print ('\\nnp.dot(A, B)')\n",
    "%timeit np.dot(A, B)\n",
    "\n",
    "print (\"\\nnp.einsum('ij,jk', A, B)\")\n",
    "%timeit np.einsum('ij,jk', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dot and python loop\n",
      "10 loops, best of 3: 19.4 ms per loop\n",
      "\n",
      "Using np.einsum('...jk,...k->...j', A_array, b_array)\n"
     ]
    }
   ],
   "source": [
    "A_array = np.random.rand(10000, 3, 3) # [A1, A2, A3, ...]\n",
    "b_array = np.random.rand(10000, 3) # [b1, b2, b3, ...]\n",
    "x_array = np.zeros((10000, 3))\n",
    "\n",
    "# np.dot(A_array, b_array)\n",
    "\n",
    "\n",
    "def use_dot(x_array):\n",
    "    for i in range(10000):\n",
    "        x_array[i] = np.dot(A_array[i], b_array[i])\n",
    "\n",
    "print ('Using dot and python loop')\n",
    "%timeit use_dot(x_array)\n",
    "\n",
    "print (\"\\nUsing np.einsum('...jk,...k->...j', A_array, b_array)\")\n",
    "%timeit np.einsum('...jk,...k->...j', A_array, b_array)\n",
    "\n",
    "use_dot(x_array)\n",
    "x_einsum_array1 = np.einsum('...jk,...k->...j', A_array, b_array)\n",
    "assert np.allclose(x_array, x_einsum_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.einsum('...ij,...jk,...kl,...l->...i', A_array, A_array, A_array, b_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If performance and not code style is your primary concern, you might still be better off with dot and the loop (depending on your specific data and system environment). In contrast to einsum, dot can take advantage of BLAS and will often multithread automatically.\n",
    "\n",
    "# Methods in the oven: `numpy.core.umath_tests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dir(np.core.umath_tests)\n",
    "#print np.version.version\n",
    "from numpy.core.umath_tests import inner1d\n",
    "dir(np.core.umath_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_array = np.random.rand(1000000, 3) # [a1, a2, a3, ...]\n",
    "b_array = np.random.rand(1000000, 3) # [b1, b2, b3, ...]\n",
    "\n",
    "print (\"np.einsum('...k,...k', a_array, b_array)\")\n",
    "%timeit np.einsum('...k,...k', a_array, b_array)\n",
    "\n",
    "# Another one, it seems really advanced... but also faster...\n",
    "print ('\\nnp.core.umath_tests.inner1d(a_array, b_array)')\n",
    "%timeit np.core.umath_tests.inner1d(a_array, b_array)\n",
    "\n",
    "assert np.allclose(np.einsum('...k,...k', a_array, b_array), np.core.umath_tests.inner1d(a_array, b_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses the [Generalized Universal Function API](http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html), but this will be for another book meeting.\n",
    "\n",
    ">There is a general need for looping over not only functions on scalars but also over **functions on vectors** (or arrays). This concept is realized in Numpy by generalizing the universal functions (ufuncs).\n",
    "\n",
    "New **hidden** methods in this [pull request](https://github.com/numpy/numpy/pull/3220/files). They all use the method `gufunc(..., **kw_args)`.\n",
    "\n",
    "In `numpy/linalg/_gufuncs_linalg.py`,\n",
    "```\n",
    "=======================\n",
    " gufuncs_linalg module\n",
    "=======================\n",
    "\n",
    "Linear Algebra functions implemented as gufuncs, so they broadcast.\n",
    "\n",
    "warning::** This module is only for testing, the functionality will be integrated into numpy.linalg proper.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matrix_multiply` wins for **matrix-matrix** vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_array = np.random.rand(10000, 4, 3) # [A1, A2, A3, ...]\n",
    "B_array = np.random.rand(10000, 3, 4) # [A1, A2, A3, ...]\n",
    "\n",
    "print (\"np.einsum('...ij,...jk->...ik', A_array, B_array)\")\n",
    "%timeit np.einsum('...ij,...jk->...ik', A_array, B_array)\n",
    "\n",
    "# Another one, it seems really advanced... but also faster...\n",
    "print ('\\nnp.core.umath_tests.matrix_multiply(A_array, B_array)')\n",
    "%timeit np.core.umath_tests.matrix_multiply(A_array, B_array)\n",
    "\n",
    "assert np.allclose(np.einsum('...ij,...jk->...ik', A_array, B_array), np.core.umath_tests.matrix_multiply(A_array, B_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`einsum` wins for **matrix-vector** vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_array = np.random.rand(10000, 4, 4) # [A1, A2, A3, ...]\n",
    "b_array = np.random.rand(10000, 4) # [b1, b2, b3, ...]\n",
    "\n",
    "print (\"\\nUsing np.einsum('...jk,...k->...j', A_array, b_array)\")\n",
    "%timeit np.einsum('...jk,...k->...j', A_array, b_array)\n",
    "\n",
    "print (\"\\nnp.core.umath_tests.matrix_multiply(A_array, b_array)\")\n",
    "%timeit np.core.umath_tests.matrix_multiply(A_array, b_array[:, :, np.newaxis])[:,:,0]\n",
    "\n",
    "x_einsum = np.einsum('...jk,...k->...j', A_array, b_array)\n",
    "x_matrix_multiply = np.core.umath_tests.matrix_multiply(A_array, b_array[:, :, np.newaxis])[:,:,0]\n",
    "assert np.allclose(x_einsum, x_matrix_multiply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is only one operand, no axes are summed, and no output parameter is provided, a view into the operand is returned instead of a new array. Thus, taking the diagonal as `np.einsum('ii->i', a)` produces a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 2.0, 4.0, 3.0],\n",
    "              [1.0, 0.0, 2.0, 0.0],\n",
    "              [1.0, 1.0, 1.1, 0.0],\n",
    "              [2.0, 2.0, 1.0, 1.0]])\n",
    "d = np.einsum('ii->i', A)\n",
    "\n",
    "#d[0] = 1000 # Doesn't work, it's a view!\n",
    "print(d)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Products with more than 2 arrays...\n",
    "\n",
    "A_array = np.random.rand(2, 3, 3) # [A1, A2, A3, ...]\n",
    "b_array = np.random.rand(2, 3) # [b1, b2, b3, ...]\n",
    "\n",
    "# \"A*A*b\" = [dot(dot(A1,A1), b1), dot(dot(A2,A2), b2), ...]\n",
    "val2 = np.einsum('...ij,...jk,...k->...ik', A_array, A_array, b_array)\n",
    "print(val2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:petsc_debug]",
   "language": "python",
   "name": "conda-env-petsc_debug-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
